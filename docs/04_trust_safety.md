# Trust & Safety Model

## Overview
Kori is a user-to-user system operating across borders.
Trust is enforced through **architecture**, not moderation at scale.

The goal is to:
- discourage abuse by design
- make honest behavior the easiest path
- preserve user dignity and platform neutrality

---

## Trust Layers

### 1. Identity Context (Soft)
- Account age
- Participation history
- Contribution quality
- Peer signals (likes, responses, confirmations)

No real-name or KYC requirement at the base layer.

---

### 2. Action Verification (Medium)
Used for value-triggering events:
- mutual confirmation (both sides)
- time-based completion
- optional location consistency

These checks are *contextual*, not permanent surveillance.

---

### 3. Economic Friction (Hard)
Abuse is discouraged through:
- rate limits
- diminishing rewards
- one-action-one-reward constraints
- delayed unlocks for new accounts

This avoids punitive bans where possible.

---

## Anti-Abuse Principles

### Closed-Loop Rewards
- C-tokens are non-cashout
- No direct arbitrage
- Value accrues through continued participation

This prevents farming and bot economies.

---

### Click Integrity
- Referral rewards require unique, valid sessions
- Repeat or automated clicks are ignored
- Suspicious patterns are logged, not immediately punished

---

### Progressive Trust
- New users have limited influence
- Trust increases through consistent, verified behavior
- High-trust users gain visibility, not raw power

---

## Disputes & Resolution
- Most interactions are designed to be low-stakes
- For paid experiences:
  - escrow delays allow dispute windows
  - resolution rules are predefined and auditable
- Kori avoids subjective moderation where possible

---

## Data & Privacy
- No selling of personal data
- Minimal storage of location signals
- Trust signals are contextual, not global reputation scores

---

## Status
Trust & safety is iterative.
This document defines principles and primitives, not final enforcement thresholds.
